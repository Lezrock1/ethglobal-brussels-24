{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6urY5JXaE11m"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.models import resnet18\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision import datasets\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.optim as optim\n",
        "\n",
        "# Überprüfe, ob PyTorch verfügbar ist\n",
        "print(\"PyTorch Version:\", torch.__version__)\n",
        "print(\"CUDA verfügbar:\", torch.cuda.is_available())\n",
        "print(\"CUDA-Version:\", torch.version.cuda)\n",
        "print(\"Aktuelle GPU:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"Keine GPU\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "# Transformations für den Datensatz\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor()  # Wandelt die Bilder von PIL-Images oder NumPy-Arrays in Tensors um.\n",
        "                            # Die Werte der Pixel werden automatisch von [0, 255] auf den Bereich [0, 1] skaliert\n",
        "    #, transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "# CIFAR-10 laden\n",
        "batch_size = 64\n",
        "test_set = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "test_loader = torch.utils.data.DataLoader(test_set, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Lade das vortrainierte ResNet-18 Modell\n",
        "model = resnet18(pretrained=True)\n",
        "\n",
        "# Passe die finale Schicht für CIFAR-10 an, da ResNet-18 für ImageNet mit 1000 Klassen trainiert wurde\n",
        "model.fc = nn.Linear(512, 10)  # CIFAR-10 hat 10 Klassen\n",
        "\n",
        "# Setze das Modell in den Evaluierungsmodus\n",
        "model.eval()\n",
        "\n",
        "# Bestimme das device (GPU oder CPU)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "print(\"used  device: \", device)\n",
        "\n",
        "# Verschiebe das Modell auf das richtige device (CPU oder GPU)\n",
        "model = model.to(device)\n",
        "'''\n"
      ],
      "metadata": {
        "id": "kJ_V4CN0FDgu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Daten-Transformationen\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=4),  # Zufälliger Zuschnitt\n",
        "    transforms.RandomHorizontalFlip(),     # Spiegeln\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "# Daten laden\n",
        "train_set = datasets.CIFAR10(root='./data', train=True, download=True, transform=train_transform)\n",
        "test_set = datasets.CIFAR10(root='./data', train=False, download=True, transform=test_transform)\n",
        "\n",
        "class_names = [\n",
        "    'airplane', 'automobile', 'bird', 'cat', 'deer',\n",
        "    'dog', 'frog', 'horse', 'ship', 'truck']\n",
        "\n",
        "batch_size = 64\n",
        "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False)"
      ],
      "metadata": {
        "id": "-GYXVWZEziLX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Lade das vortrainierte ResNet-18 Modell\n",
        "model = resnet18(pretrained=True)\n",
        "\n",
        "# Passe die finale Schicht an\n",
        "model.fc = nn.Linear(512, 10)  # CIFAR-10 hat 10 Klassen\n",
        "\n",
        "# Device setzen\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = model.to(device)"
      ],
      "metadata": {
        "id": "V24wDO0OziUQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loss-Funktion\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Optimierer\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=5e-4)\n",
        "\n",
        "# Learning Rate Scheduler (optional, für bessere Ergebnisse)\n",
        "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.1)"
      ],
      "metadata": {
        "id": "29maznA6zib_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Trainingsschleife"
      ],
      "metadata": {
        "id": "pnHEGvwV0JSk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 5\n",
        "for epoch in range(epochs):\n",
        "    model.train()  # Setze das Modell in den Trainingsmodus\n",
        "    running_loss = 0.0\n",
        "\n",
        "    for inputs, labels in train_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()  # Gradienten zurücksetzen\n",
        "        outputs = model(inputs)  # Vorhersagen\n",
        "        loss = criterion(outputs, labels)  # Loss berechnen\n",
        "        loss.backward()  # Backpropagation\n",
        "        optimizer.step()  # Optimierung\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    scheduler.step()  # Learning Rate anpassen (falls Scheduler verwendet wird)\n",
        "\n",
        "    # Trainingsgenauigkeit berechnen\n",
        "    model.eval()  # Setze das Modell in den Evaluierungsmodus\n",
        "    correct_train = 0\n",
        "    total_train = 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in train_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total_train += labels.size(0)\n",
        "            correct_train += (predicted == labels).sum().item()\n",
        "    train_accuracy = 100 * correct_train / total_train\n",
        "\n",
        "    # Validierungsgenauigkeit berechnen\n",
        "    correct_val = 0\n",
        "    total_val = 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in test_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total_val += labels.size(0)\n",
        "            correct_val += (predicted == labels).sum().item()\n",
        "    val_accuracy = 100 * correct_val / total_val\n",
        "\n",
        "    # Ausgabe der Ergebnisse\n",
        "    print(f'Epoch {epoch+1}/{epochs}')\n",
        "    print(f'    Loss: {running_loss / len(train_loader):.4f}')\n",
        "    print(f'    Train Accuracy: {train_accuracy:.2f}%')\n",
        "    print(f'    Validation Accuracy: {val_accuracy:.2f}%')\n"
      ],
      "metadata": {
        "id": "bHNvPan40E4O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Speichern und Laden des Modells"
      ],
      "metadata": {
        "id": "wgouT3Tr0Qpu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Speichern\n",
        "torch.save(model.state_dict(), 'resnet18_cifar10.pth')\n",
        "\n",
        "# Laden\n",
        "model.load_state_dict(torch.load('resnet18_cifar10.pth'))\n",
        "model.eval()"
      ],
      "metadata": {
        "id": "ohoS7gCt0FAC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Accuracy berechnen\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "# Deaktiviere Gradient-Berechnungen für die Inferenz\n",
        "with torch.no_grad():\n",
        "    # Durchlaufe den Testdatensatz\n",
        "    for images, labels in test_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        # Modellvorhersagen durchführen\n",
        "        outputs = model(images)\n",
        "\n",
        "        # Bestimme die Vorhersage (Index mit der höchsten Wahrscheinlichkeit)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "        # Anzahl der richtigen Vorhersagen zählen\n",
        "        total += labels.size(0)  # Die Anzahl der Bilder im Batch\n",
        "        correct += (predicted == labels).sum().item()  # Die Anzahl der richtigen Vorhersagen\n",
        "\n",
        "# Berechne die Accuracy\n",
        "accuracy = 100 * correct / total\n",
        "print(f'Accuracy des Modells auf den Testdaten: {accuracy:.2f}%')"
      ],
      "metadata": {
        "id": "arn-nz4sFDu-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Wir beginnen mit einer Fast Gradient Sign Method (FGSM) Attacke:"
      ],
      "metadata": {
        "id": "G8X66s2OOU3Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def fgsm_attack(image, epsilon, data_grad):\n",
        "    \"\"\"\n",
        "    Führt eine FGSM-Attacke aus.\n",
        "    :param image: Eingabebild\n",
        "    :param epsilon: Perturbationsstärke\n",
        "    :param data_grad: Gradienten der Eingabe\n",
        "    :return: Angegriffenes Bild\n",
        "    \"\"\"\n",
        "    sign_data_grad = data_grad.sign()  # Gradienten in Vorzeichen umwandeln\n",
        "    perturbed_image = image + epsilon * sign_data_grad  # Perturbation hinzufügen\n",
        "    perturbed_image = torch.clamp(perturbed_image, -1, 1)  # Pixelwerte begrenzen\n",
        "    return perturbed_image\n"
      ],
      "metadata": {
        "id": "R_YRkcdsFDyW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epsilon = 8/255  # to normalized Data, plots of various epsilons\n",
        "correct = 0\n",
        "adv_examples_fgsm = []\n",
        "\n",
        "for data, target in test_loader:\n",
        "    data, target = data.to(device), target.to(device)\n",
        "    data.requires_grad = True  # Eingabebild für Gradienten vorbereiten\n",
        "\n",
        "    # Vorhersage und Verlust berechnen\n",
        "    output = model(data)\n",
        "    loss = nn.CrossEntropyLoss()(output, target)\n",
        "\n",
        "    # Gradienten berechnen\n",
        "    model.zero_grad()\n",
        "    loss.backward()\n",
        "    data_grad = data.grad.data\n",
        "\n",
        "    # FGSM-Attacke durchführen\n",
        "    perturbed_data = fgsm_attack(data, epsilon, data_grad)\n",
        "\n",
        "    # Neue Vorhersage\n",
        "    output = model(perturbed_data)\n",
        "    pred = output.max(1, keepdim=True)[1]\n",
        "    correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    # Speichere 5 Beispiele\n",
        "    if len(adv_examples_fgsm) < 5:\n",
        "        adv_ex = perturbed_data[0].detach().cpu().numpy()\n",
        "        adv_examples_fgsm.append((epsilon, pred[0].item(), target[0].item(), adv_ex))\n",
        "\n",
        "# Genauigkeit berechnen\n",
        "final_acc = correct / len(test_loader.dataset)\n",
        "print(f\"Test Accuracy mit Fast Gradient Sign Method (FGSM) Attacke = {final_acc * 100:.2f}%    (epsilon: {epsilon})\")\n"
      ],
      "metadata": {
        "id": "eShKTLHfFD1N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oIqCQllqE11q"
      },
      "outputs": [],
      "source": [
        "def imshow(img):\n",
        "    # Falls das Bild ein PyTorch Tensor ist, normalisieren und in numpy Array umwandeln\n",
        "    if isinstance(img, torch.Tensor):\n",
        "        img = img / 2 + 0.5  # Normalisierung zurücksetzen\n",
        "        npimg = img.numpy()\n",
        "    else:\n",
        "        # Falls es schon ein numpy Array ist, einfach darauf zugreifen\n",
        "        npimg = img\n",
        "\n",
        "    # Transponiere die Dimensionen von (C, H, W) zu (H, W, C)\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.show()\n",
        "\n",
        "print(\"Angegriffene Bilder:\")\n",
        "for epsilon, pred, true, ex in adv_examples_fgsm:\n",
        "    print(f\"Epsilon: {epsilon}\\tVorhersage: {class_names[pred]}\\tEchtes Label: {class_names[true]}\")\n",
        "    imshow(ex)  # Zeigt das Bild an\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Jetzt führen wir eine Projected Gradient Descent (PGD) Attacke durch:"
      ],
      "metadata": {
        "id": "d8QACzOvOiJj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def pgd_attack(model, image, label, epsilon, alpha, num_iter):\n",
        "    \"\"\"\n",
        "    Führt eine PGD-Attacke aus.\n",
        "\n",
        "    :param model: Das zu attackierende Modell\n",
        "    :param image: Eingabebild\n",
        "    :param label: Wahres Label des Bildes\n",
        "    :param epsilon: Maximale Perturbation (L∞-Norm)\n",
        "    :param alpha: Schrittweite der Perturbation\n",
        "    :param num_iter: Anzahl der Iterationen\n",
        "    :return: Angegriffenes Bild\n",
        "    \"\"\"\n",
        "    # Stelle sicher, dass das Bild gradient-fähig ist\n",
        "    perturbed_image = image.clone().detach().requires_grad_(True)\n",
        "\n",
        "    for _ in range(num_iter):\n",
        "        # Setze die Gradienten auf 0\n",
        "        model.zero_grad()\n",
        "\n",
        "        # Berechne die Vorhersage und den Verlust\n",
        "        output = model(perturbed_image)\n",
        "        loss = nn.CrossEntropyLoss()(output, label)\n",
        "\n",
        "        # Berechne die Gradienten\n",
        "        loss.backward()\n",
        "        data_grad = perturbed_image.grad.data\n",
        "\n",
        "        # Berechne die neue Perturbation (ähnlich wie FGSM, aber iterativ)\n",
        "        perturbed_image = perturbed_image + alpha * data_grad.sign()\n",
        "\n",
        "        # Projektion der Perturbation in den erlaubten Epsilon-Bereich\n",
        "        perturbation = torch.clamp(perturbed_image - image, -epsilon, epsilon)\n",
        "        perturbed_image = torch.clamp(image + perturbation, -1, 1).detach()\n",
        "        perturbed_image.requires_grad = True  # Gradient wieder aktivieren\n",
        "\n",
        "    return perturbed_image\n"
      ],
      "metadata": {
        "id": "03LHt99nONMC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Parameter der PGD-Attacke\n",
        "epsilon = 8 / 255  # Maximale Perturbation\n",
        "alpha = 2 / 255    # Schrittgröße pro Iteration\n",
        "num_iter = 10      # Anzahl der Iterationen\n",
        "\n",
        "correct = 0\n",
        "adv_examples_pgd = []\n",
        "\n",
        "for data, target in test_loader:\n",
        "    # Lade Bilder und Labels auf das richtige Gerät\n",
        "    data, target = data.to(device), target.to(device)\n",
        "\n",
        "    # Wende die PGD-Attacke auf jedes Bild im Batch an\n",
        "    perturbed_data = pgd_attack(model, data, target, epsilon, alpha, num_iter)\n",
        "\n",
        "    # Vorhersage mit dem Modell auf die angegriffenen Bilder\n",
        "    output = model(perturbed_data)\n",
        "    pred = output.max(1, keepdim=True)[1]  # Klasse mit der höchsten Wahrscheinlichkeit\n",
        "    correct += pred.eq(target.view_as(pred)).sum().item()  # Zähle korrekte Vorhersagen\n",
        "\n",
        "    # Speichere 10 Beispiele\n",
        "    if len(adv_examples_pgd) < 10:\n",
        "        for i in range(min(len(data), 10 - len(adv_examples_pgd))):\n",
        "            adv_ex = perturbed_data[i].detach().cpu().numpy()\n",
        "            adv_examples_pgd.append((epsilon, pred[i].item(), target[i].item(), adv_ex))\n",
        "\n",
        "# Genauigkeit berechnen\n",
        "final_acc = correct / len(test_loader.dataset)\n",
        "print(f\"Test Accuracy mit Projected Gradient Descent (PGD) Attacke = {final_acc * 100:.2f}%    (epsilon: {epsilon})\")\n"
      ],
      "metadata": {
        "id": "JfqrkwI4ONYw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def imshow(img):\n",
        "    # Falls das Bild ein PyTorch Tensor ist, normalisieren und in numpy Array umwandeln\n",
        "    if isinstance(img, torch.Tensor):\n",
        "        img = img / 2 + 0.5  # Normalisierung zurücksetzen\n",
        "        npimg = img.numpy()\n",
        "    else:\n",
        "        # Falls es schon ein numpy Array ist, einfach darauf zugreifen\n",
        "        npimg = img\n",
        "\n",
        "    # Transponiere die Dimensionen von (C, H, W) zu (H, W, C)\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "print(\"Angegriffene Bilder:\")\n",
        "for epsilon, pred, true, ex in adv_examples_pgd:\n",
        "    print(f\"Epsilon: {epsilon}\\tVorhersage: {class_names[pred]}\\tEchtes Label: {class_names[true]}\")\n",
        "    imshow(ex)  # Zeigt das Bild an\n"
      ],
      "metadata": {
        "id": "eR7gNB1OONg1"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}